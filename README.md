# Neural Networks Learning Series

A hands-on journey through neural network implementation using Python and NumPy.

## Chapters

### Chapter 1: Neural Network Fundamentals
Single neuron to multi-layer implementation with manual calculations and programmatic solutions.
- Key formula: `output = Σ(input_i × weight_i) + bias`
- Manual vs programmatic implementations
- Prerequisites: Basic Python, elementary linear algebra

### Chapter 2: Neural Network Layers in NumPy
NumPy implementation progressing from single neuron to batch processing.
- Single neuron, multi-neuron layers, batch processing
- Matrix operations: `Y = XW^T + b`
- Matrix multiplication, transpose operations, broadcasting

### Chapter 3: Multi-Layer Forward Pass
3-layer neural network forward pass implementation.
- Architecture: Input(4) → Hidden1(3) → Hidden2(3) → Output(2)
- Direct matrix operations and loop-based approaches
- Batch processing of 7 samples with 4 features

### Chapter 4: Dataset Generator & Dense Layer
Dataset creation and basic layer construction.
- Spiral dataset generation (single/multi-class)
- Dense layer implementation with forward pass
- Integration examples using synthetic data

### Chapter 5: Activation Functions & NumPy Operations
Core activation functions and NumPy array operations.
- Activation functions: ReLU, Leaky ReLU, Softmax, Tanh, Sigmoid
- NumPy axis operations and broadcasting concepts
- 2-layer network example with spiral data

## Prerequisites
- Python 3.x
- NumPy, matplotlib
- Basic understanding of lists, loops, and linear algebra

---

*Progressive learning from mathematical foundations to practical neural network implementation.*